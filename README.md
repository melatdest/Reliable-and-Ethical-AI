# Reliable and Ethical AI

This repository contains presentation materials I developed for a seminar on **balancing human oversight and critical examination of human oversight in AI systems**, with reference to regulatory frameworks such as the **EU AI Act**.

## ðŸ“‚ Contents

- **Human Oversight in AI Alignment**  
  A presentation exploring human oversight as an alignment technique, covering its strengths, limitations, and integration with other safety mechanisms like interpretability tools. It also introduces control paradigms such as Human-in-the-Loop (HITL), Human-on-the-Loop (HOTL), and Human-out-of-the-Loop (HOOTL).

- **Critical Perspectives on Oversight and Regulation**  
  A critical examination of the effectiveness and assumptions behind human oversight, drawing from the EU AI Act and debates on systemic risk, value lock-in, and democratic deliberation in AI governance.

## ðŸ’¡ Why this matters

As AI systems grow more capable, ensuring their alignment with human values becomes increasingly important. This work reflects my ongoing exploration of ethical and reliable AI development, especially in contexts where human input is central yet fallible.

## ðŸ“Ž Note

These are presentation materials only. For now, I am sharing this repository to demonstrate my engagement with real-world AI ethics, governance, and safety discussions. More detailed project work may follow in future iterations.

